<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Learn English for Kids</title>
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js/dist/tesseract.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 0;
            padding: 0;
            background-color: #f0f8ff;
        }
        video {
            width: 100%;
            max-width: 600px;
            margin: 20px auto;
            border: 2px solid #333;
            border-radius: 8px;
        }
        ul {
            list-style: none;
            padding: 0;
        }
        li {
            display: flex;
            align-items: center;
            margin: 10px;
            padding: 10px;
            background: #e6f7ff;
            border: 1px solid #b3d9ff;
            border-radius: 5px;
        }
        img {
            width: 50px;
            height: 50px;
            margin-right: 10px;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <h1>Learn English for Kids</h1>
    <video id="video" autoplay></video>
    <ul id="wordList"></ul>

    <script>
        const video = document.getElementById('video');
        const wordList = document.getElementById('wordList');
        const spokenWords = new Set();

        // Access the camera
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(err => console.error('Error accessing camera:', err));

        // Recognize text and process it
        async function recognizeText() {
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            const { data: { text } } = await Tesseract.recognize(canvas, 'eng');
            const words = text.split(/\s+/).filter(word => word.length > 2);

            for (const word of words) {
                if (!spokenWords.has(word)) {
                    spokenWords.add(word);
                    speakWord(word);
                    addWordToList(word);
                }
            }

            setTimeout(recognizeText, 2000); // Repeat every 2 seconds
        }

        // Speak the word
        function speakWord(word) {
            const utterance = new SpeechSynthesisUtterance(word);
            utterance.lang = 'en-US';
            speechSynthesis.speak(utterance);
        }

        // Add word and image to the list
        async function addWordToList(word) {
            const listItem = document.createElement('li');
            const img = document.createElement('img');
            const textNode = document.createTextNode(word);

            // Fetch a related image
            try {
                const response = await fetch(`https://source.unsplash.com/50x50/?${word}`);
                img.src = response.url;
            } catch (err) {
                img.src = 'https://via.placeholder.com/50'; // Placeholder image
            }

            listItem.appendChild(img);
            listItem.appendChild(textNode);
            wordList.appendChild(listItem);
        }

        // Start recognition
        video.addEventListener('loadeddata', recognizeText);
    </script>
</body>
</html>
